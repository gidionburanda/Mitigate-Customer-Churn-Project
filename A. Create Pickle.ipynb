{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1BxLar8At7ojwjk3hCwzsYI7_-XxrNLs-","authorship_tag":"ABX9TyMqWD02VmbzLNcAly/wzju0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"dWWa8HbaG_QY","colab":{"base_uri":"https://localhost:8080/","height":407},"outputId":"dbcba03f-9780-44b8-a471-df93e3424942","executionInfo":{"status":"error","timestamp":1670152028032,"user_tz":-420,"elapsed":26835,"user":{"displayName":"Group Italy","userId":"13069925011284714675"}}},"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-84b21a83fa0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    122\u001b[0m       'TBE_EPHEM_CREDS_ADDR'] if ephemeral else _os.environ['TBE_CREDS_ADDR']\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    125\u001b[0m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["#1\n","import numpy as np \n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import warnings\n","%matplotlib inline\n","plt.style.use('seaborn-whitegrid')\n","plt.style.use('fivethirtyeight')\n","warnings.filterwarnings('ignore')\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","data_customer=pd.read_csv('/content/drive/MyDrive/Mockup Datasets/customer.csv')\n","data_product=pd.read_csv('/content/drive/MyDrive/Mockup Datasets/product.csv', error_bad_lines=False)\n","data_transactions=pd.read_csv('/content/drive/MyDrive/Mockup Datasets/transactions.csv')\n","data_click_stream=pd.read_csv('/content/drive/MyDrive/Mockup Datasets/click_stream.csv')\n","\n","customer_clean=data_customer.dropna()\n","click_clean=data_click_stream.dropna()\n","product_clean=data_product.dropna()\n","transaction_clean=data_transactions.dropna()\n","\n","#1. Merge data customer dengan transaction menggunakan customer_id\n","customer_and_transactions = customer_clean.merge(transaction_clean, on='customer_id', validate='m:m')\n","\n","#2. Merge data customer_and_transactions dengan data click stream menggunakan session_id\n","customer_transactions_click = customer_and_transactions.merge(click_clean, on='session_id', validate='m:m')\n","\n","#2.1. Mengambil data product id dari kolom product_metadata\n","customer_transactions_click['product_id']=customer_transactions_click.product_metadata.str[15:21]\n","\n","\n","data1_clean=customer_transactions_click.dropna()\n","product_clean.rename(columns = {'id':'product_id'}, inplace = True)\n","\n","#3. Merging data1 dengan data product melalui product_id\n","data1_clean['product_id'] = data1_clean['product_id'].astype(str)\n","product_clean['product_id'] = product_clean['product_id'].astype(str)\n","customer_transactions_click_product = data1_clean.merge(product_clean, on='product_id', how='outer')\n","\n","data_final=customer_transactions_click_product\n","\n","# CREATE VARIABLE IS_CHURN\n","data_final = data_final.dropna(subset=['created_at'])\n","\n","data_final['created_at'] = data_final['created_at'].str.replace(\"T\",\" \")\n","data_final['created_at'] = data_final['created_at'].str.replace(\"Z\",\"\")\n","\n","data_final['created_at']=pd.to_datetime(data_final['created_at'])\n","\n","data_final2=data_final.drop_duplicates(subset=['customer_id'], keep='last').sort_values(by='customer_id')\n","\n","import datetime as dt\n","present_day = data_final2['created_at'].max() \n","data_final2['recency']= data_final2['created_at'].apply(lambda x: (present_day - x).days)\n","\n","data_final2['is_churn'] = np.where((data_final2['recency'] >= 30) , 1, 0)\n","\n","churn_customer = data_final2.drop_duplicates(subset='created_at').reset_index()\n","\n","#CREATE INDEPENDENT VARIABLE\n","#Data usia\n","data_final2['birthdate'] = pd.to_datetime(data_final2.birthdate)\n","from datetime import datetime\n","data_final2['Today'] = datetime.now().date()\n","data_final2['Today'] = pd.to_datetime(data_final2.Today)\n","data_final2['Age']= data_final2.Today - data_final2.birthdate\n","data_final2['new']=data_final2.Age.dt.days\n","data_final2['Age_inYear']=data_final2.new/365\n","data_final2['Age_inYear2']=data_final2['Age_inYear'].astype(int)\n","data_final2['age'] = data_final2['Age_inYear2']\n","\n","#Data jenis kelamin\n","data_final2['isFemale'] = np.where(\n","      (data_final2['gender_x']== 'F') , 1, 0\n","    )\n","\n","#Data tipe perangkat\n","data_final2['is_iOS'] = np.where(\n","      (data_final2['device_type']== 'iOS') , 1, 0\n","    )\n","\n","\n","\n","\n","#2\n","dff1=data_final2\n","dff=dff1.drop(['gender_y', 'masterCategory','subCategory','articleType','baseColour','season',\n","         'year','usage','productDisplayName','Age_inYear','Age','age','new'], axis=1)\n","\n","#dft['created_at] = pd.to_datetime(dft['created_at],utc=True)\n","dff['created_at'] = pd.to_datetime(dff['created_at']).dt.tz_localize(None)\n","\n","#dft['created_hour']=dft['created_at'].dt.hour\n","dff['created_day']=dff['created_at'].dt.day_name()\n","dff['created_month_year'] = dff['created_at'].apply(lambda x: x.strftime('%Y-%m')) \n","dff['created_year']=dff['created_at'].dt.year\n","dff['created_month']=dff['created_at'].dt.month_name()\n","\n","dff['created_time'] = (dff['created_at'].dt.hour % 24 + 4) // 4\n","dff['created_time'].replace({1: 'Late Night',\n","                      2: 'Early Morning',\n","                      3: 'Morning',\n","                      4: 'Noon',\n","                      5: 'Evening',\n","                      6: 'Night'}, inplace=True)\n","mod = dff.copy()\n","\n","replacements = {'payment_status': {'Success': 1, 'Failed': 0}, \n","                'traffic_source': {'WEB': 0, 'MOBILE': 1}}\n","\n","mod.replace(replacements, inplace=True)\n","\n","# get the dummies and store it in a variable\n","dummies = pd.get_dummies(mod[['created_time','created_day','event_name','promo_code','payment_method']])\n"," \n","# Concatenate the dummies to original dataframe\n","mod2 = pd.concat([mod, dummies], axis='columns')\n"," \n","# drop the values\n","mod2_1=mod2.drop(['created_time','created_day','event_name','promo_code','payment_method'], axis='columns')\n","\n","mod3=mod2_1[['home_location_lat','home_location_long','promo_amount','shipment_fee',\n","         'shipment_location_lat','shipment_location_long','total_amount','recency',\n","         'is_churn','Age_inYear2','isFemale','is_iOS','created_time_Early Morning', \n","         'created_time_Evening','created_time_Late Night', 'created_time_Morning', \n","         'created_time_Night','created_time_Noon', 'created_day_Friday', 'created_day_Monday',\n","         'created_day_Saturday', 'created_day_Sunday', 'created_day_Thursday',\n","         'created_day_Tuesday', 'created_day_Wednesday','event_name_ADD_TO_CART', \n","         'event_name_BOOKING', 'event_name_SEARCH','promo_code_AZ2022', 'promo_code_BUYMORE', \n","         'promo_code_LIBURDONG','promo_code_SC2022', 'promo_code_STARTUP', 'promo_code_WEEKENDMANTAP',\n","         'promo_code_WEEKENDSERU', 'promo_code_XX2022','payment_method_Credit Card', \n","         'payment_method_Debit Card','payment_method_Gopay', 'payment_method_LinkAja', \n","         'payment_method_OVO']]\n","\n","#3\n","#Keeping necessary column\n","data=mod3\n","\n","#Choose variable\n","data_xy2=data[['promo_amount', 'shipment_fee', 'total_amount', 'Age_inYear2', 'isFemale', 'is_iOS', 'payment_method_OVO', \n","               'created_time_Noon', 'created_day_Tuesday', 'event_name_ADD_TO_CART', 'promo_code_AZ2022', 'is_churn']]\n","\n","y= data_xy2['is_churn']\n","X= data_xy2.drop(['is_churn'],1)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"status":"aborted","timestamp":1670152028036,"user_tz":-420,"elapsed":7,"user":{"displayName":"Group Italy","userId":"13069925011284714675"}},"id":"c1DjfFSWplZK"},"outputs":[],"source":["#XGB TUNING HYPERPARAMETER\n","#evaluation\n","from sklearn import metrics\n","from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n","from sklearn.metrics import make_scorer,accuracy_score,roc_auc_score,precision_score,recall_score,f1_score,log_loss\n","from sklearn.metrics import confusion_matrix\n","from numpy import loadtxt\n","from xgboost import XGBClassifier\n","\n","# import packages for hyperparameters tuning\n","from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n","\n","model = XGBClassifier()\n","space={'max_depth': hp.choice(\"max_depth\", np.arange(3, 18, 1, dtype=int)),\n","        'gamma': hp.uniform ('gamma', 1,9),\n","        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n","        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n","        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n","        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n","        'n_estimators': 180,\n","        'seed': 0\n","    }\n","\n","#Objective function\n","import xgboost as xgb\n","def objective(space):\n","    clf=xgb.XGBClassifier(\n","                    n_estimators =space['n_estimators'], max_depth = int(space['max_depth']), gamma = space['gamma'],\n","                    reg_alpha = int(space['reg_alpha']),min_child_weight=int(space['min_child_weight']),\n","                    colsample_bytree=int(space['colsample_bytree']))\n","    \n","    evaluation = [( X_train, y_train), ( X_test, y_test)]\n","    \n","    clf.fit(X_train, y_train,\n","            eval_set=evaluation, eval_metric=\"auc\",\n","            early_stopping_rounds=10,verbose=False)\n","    \n","\n","    pred = clf.predict(X_test)\n","    accuracy = accuracy_score(y_test, pred>0.5)\n","    print (\"SCORE:\", accuracy)\n","    return {'loss': -accuracy, 'status': STATUS_OK }\n","\n","#Optimize algorithm\n","trials = Trials()\n","\n","best_hyperparams = fmin(fn = objective,\n","                        space = space,\n","                        algo = tpe.suggest,\n","                        max_evals = 100,\n","                        trials = trials)\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import train_test_split \n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","from sklearn.model_selection import StratifiedKFold \n","\n","xgb_classifier = XGBClassifier()\n","xgbc = StratifiedKFold(n_splits=2)\n","\n","xgbc = GridSearchCV(estimator=xgb_classifier, \n","                 param_grid={\n","                     'max_depth': [hp.quniform(\"max_depth\", 3, 18, 1)],\n","                     'gamma': [hp.uniform ('gamma', 1,9)],\n","                     'reg_alpha' : [hp.quniform('reg_alpha', 40,180,1)],\n","                     'reg_lambda' : [hp.uniform('reg_lambda', 0,1)],\n","                     'colsample_bytree' : [hp.uniform('colsample_bytree', 0.5,1)],\n","                     'min_child_weight' : [hp.quniform('min_child_weight', 0, 10, 1)],\n","                     'n_estimators': [180],\n","                     'seed': [0]\n","                      },\n","                 \n","                 cv = StratifiedKFold(n_splits=2), \n","                 verbose = 4)\n","\n","tuning_model = XGBClassifier(**best_hyperparams)\n","\n","#Training model\n","model_fit = tuning_model.fit(X_train,y_train)\n","\n","#model performance using train dataset\n","y_pred_train=model_fit.predict(X_train)\n","print(classification_report(y_train,y_pred_train))\n","\n","#model performance using test dataset\n","y_pred_test=model_fit.predict(X_test)\n","print(classification_report(y_test,y_pred_test))"]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","import pickle\n","\n","sc = StandardScaler()\n","X_scaled = sc.fit_transform(X)\n","\n","filename = 'data_scaling_team_italy.pkl' \n","pickle.dump(X_scaled, open(filename, 'wb'))"],"metadata":{"id":"Q5uBDTNbkc9m","executionInfo":{"status":"aborted","timestamp":1670152028037,"user_tz":-420,"elapsed":8,"user":{"displayName":"Group Italy","userId":"13069925011284714675"}}},"execution_count":null,"outputs":[]}]}